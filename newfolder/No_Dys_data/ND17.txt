Kunstig Intelligens og LivIndledningI en mere og mere digitaliseret verden, så er vores interaktion med kunstig intelligens ikke noget nyt, her er Siri, Google assistent og robotter noget vi daglig anvender eller hører om. Robotter var noget som kun blev anvendt på fabrikker, hvorimod vi i dag ser den i vores hjem, blandt andet i form af en støvsuger eller plæneklipper. Teknologien er blevet mere levende, men hvad vil det sige at være levende? Bare fordi vi kan programmer en robot til at udføre et stykke arbejde, så er det vel ikke en tegn på at en maskine er intelligent? Hvordan definerer vi hvad der er intelligent? Er vi mennesker det eneste intelligente væsen på vores jord og kan vi overhovedet lave intelligente maskiner, og hvordan tester man det? Dette er blot nogle af de spørgsmål jeg vil prøve at besvare gennem denne opgave, med et fokus på René Descartes, Thomas Hobbes, Alan Turing og John Searle, som er nogle af de filosoffer og matematikere der har bidraget kunstig intelligens.Jeg vil gennemgå en historisk gennemgang af René Descartes og Thomas Hobbes, da de har en indflydelse på kunstig intelligens, gennem deres tanker om erkendelse og begrundelse af hvorfor man træffer valg. Derefter vil jeg berøre klassisk AI, som er en af de første typer af kunstig intelligens vi støder på gennem historien om AI. Herefter vil jeg præsenterer for den moderne AI og nogle eksempler på kunstig intelligens vi støder på i hverdagen og sammenligne dem med klassisk AI og hvilket problematikker der opstår. Til sidst vil jeg diskutere kunstig intelligens som helhed, ved brug af de belyste emner og begreber gennem opgaven, til at opnå en større forståelse.Historisk gennemgangFor at kunne besvare hvorvidt noget er intelligent, så må vi først vide hvordan vi kan erkende noget. Hvis vi ikke selv ved noget med sikkerhed, hvordan kan vi så overføre den viden til en maskine? Her kommer René Descartes (1596 - 1650) ind i billedet, som også siges at være grundlæggeren for den moderne filosofi, da han mener at al erkendelse foregår gennem ens egen bevidsthed. Her går han altså fra skepticismens påstand om hvordan mennesket kun kan erkende noget ud fra sig selv, til hvordan vi kan komme udover os selv og bevise at andre mennesker eksisterer (Koch, 1995, s.176). Han begynder derfor at betvivle alt i verden, men hvis alt var forkert, så må han jo vide at han selv er en ting, og hvis man narres til at tror noget, så kan man tænke, hvilket må betyde at man må eksistere. Cogito ergo sum, som er latinsk og som betyder "Jeg tænker, derfor er jeg" og ud fra det kunne Descartes arbejde videre med sin erkendelsesteori.Descartes opgør med renæssancens filosofi gennem hans opfattelse af viden som et materielt system. Naturen kan beskrives ud fra matematiske lovmæssigheder, eftersom det er et materielt system og denne tankegang har skabt den udvikling vi ser for den nyere
naturvidenskab (Koch, 1995, s. 177). Vi kan altså anvende matematik til at beskrive vores verden, gennem mål, vægt, geometri osv.. I renæssancen så man også ånd og sjæl som værende en del af den fysiske verden, hvor mirakler var normen og hvor ens fantasi kunne påvirke verden omkring en. Før Descartes kunne beskrive verden, så måtte han bevise at sjæl og den materielle verden er adskilt fra hinanden. Her argumentere han, at ens bevidsthed er tænkende og ikke målbar, hvorimod de fysiske ting i verden kunne måles og ikke være tænkende. I forlængelse med det, så kan objekter i den materielle verden ødelægges og forsvinde, men hvor man umiddelbart ikke kan opnå det samme med ens ånd/sjæl (Koch, 1995, s. 178).Descartes udvikler den systematiske tvivl som en metode, hvorpå man følger fire grundregler. Den første grundregel er at ikke tage noget for sandt, hvor jeg'et ikke allerede erkender det som værende sandt. Herefter ønsker Descartes at man gennem den analytiske metode opløser problemstillingen i så mange og små dele som muligt, også derefter følge regel nummer to, hvor man skal starte det sted der forekommer mest indlysende. Her er det typisk een selv man skal starte med, set med filosofiske briller, hvor man i alle andre videnskaber begynder der hvor man har noget der er fuldstændigt evident (Koch, 1995, s.179). I den tredje regel, ser man på processen, hvor man skal gå fra det simpleste og letteste til det mere komplekse og svære dele. Den sidste regel, er hvor man skal til enhver tid vide præcis hvor henne i processen man er, så intet bliver glemt.Det er altså den her systematiske metode Descartes anvender i forbindelse med hans erkendelsesteori, hvor han grunder sin generaliseret tvivl. Hvad kan man tvivle og ikke tvivle på? Her gennemgår han tre punkter henholdsvis traditionen, sansningen og logikken.Traditionen tvivler ham om, da kirkefædrene ikke kan blive enige med hinanden om hvordan man skal udlægge bibelens ord, og må derfor skabe tvivl om virkeligheden. Herefter betvivler Descartes sansningen, som er det de britiske empirister mener at al vores viden om virkeligheden kommer gennem vores sanseerfaringer og at viden sker a posteriori, altså på baggrund erfaring. Men her introducerer Descartes illusionsargumentet, som går ud på at man kan tvivle om fjerne ting, for eksempel hvis man vurderer at et tårn er rundt på lang afstand, men hvor det efterfølgende viser sig at være et ottekantet tårn, når man kommer tættere på.Ens sanser kan altså blive snydt på længere afstand, men hvad så med de sanser vi anvender på tæt afstand? Her kommer drømmeargumentet ind i spil, da han også mener vi kan tvivle på vores sanser om nære ting, for eksempel så oplever vi mange gang at når vi drømmer, så virker det som om det er virkeligheden, hvor vi kan føle, smage, høre og dufte tingene som om vi virkelige var der. Men hvorvidt om vores virkelig også er en drøm er netop begrundelsen for at de sanser vi anvender om nære ting også kan tvivles. Så alt sansning er altså noget vi ikke kan stole på, i forhold til at opnå sikker viden.Logikken er det tredje område, som Descartes betvivler om, altså om en trekant har tre kanter og at to plus to giver fire, her introducerer han den onde dæmon-argumentet. Det kunne være at der var en ond dæmon, som kunne snyde os til at tro at en trekant faktisk har fem kanter. På grund af, at vi ikke ved hvorvidt der er en gud der vil os noget godt eller en ond dæmon, så må vi afvise logikken som grundlag for sikker viden. Descartes prøver altså
igennem disse tre områder og argumenter, at bevise, at hvis vi kan tvivle om noget een gang, så er vi nødt til at tvivle generelt, for at kunne opnå sikker viden.En anden rationalist der også er vigtig at snakke om i forhold til kunstig intelligens, er Thomas Hobbes (1588 - 1679). Han er fra samme tid som Descartes, hvor han også forsøgte at indbygge en form for naturvidenskab i sin filosofiske tænkning og konstruerede et rent mekanisk system til at beskrive og forklare den fysiske verdens indretning (Koch, 1995,s. 185). Men var ikke enig med Descartes opfattelse mellem sjæl og materie, Hobbes så alt som om det var materie og var derfor også kendt som en materialist.En af hovedpointerne Hobbes om, er at mennesket handler ud fra ens følelser. Menneskets motivation til handlinger er at klare sig og overleve, altså vores selvopholdelsesdrift (Koch, 1995, s. 186). Her sammenligner han tilværelsen med et væddeløb, hvor man skal og vil så vidt muligt vinde løbet og ikke sakke bagud, ellers opstår der følelser som vrede, misundelse eller manglende kamplyst. Hobbes udvikler en lære om følelseslivet, som vi kan anvende til at forstå og forklare, hvorfor man handler på bestemte måder, da det er følelserne der påvirker os. Dette anså nogle som en form for egoisme, da man kan forstå det som om, at mennesket kun handler for sit eget bedste, men her forklarer Hobbes, at vi mennesker også kan opnå glæde af, at det går godt for andre.Selvom disse følelser kan forstås som at være årsagsbestemte, for eksempel i forhold til overlevelse, så mener han også, at der er den frie vilje. Den frie vilje, skal forstås som om, at hvis vi kan overveje vores beslutninger og derefter udføre dem, så har vi opnået den frie vilje gennem en overvejelsesproces. Hvorimod hvis vores overvejelser ikke resulterer i de handlinger vi gerne vil udføre, så har vi ikke opnået fri vilje (Koch, 1995, s. 186). Man er altså først virkelig fri, når man er determineret af sig selv og ikke determineret af noget uden for sig selv. Men det er dog derfor stadig muligt at handle frit, selvom vores handlinger er årsagsbestemte gennem vores følelser, lidenskab eller forestillinger.Descartes ser altså verden i to dele, bevidstheden og den materielle verden, og derfor en dualist, hvorimod Hobbes er som tidligere nævnt materialist. Men selvom de ser anderledes på verden på nogle punkter, så er de enige i at det karakteristiske for den fysiske verden er dens målbarhed, men hvor der opstår nogle umålelige egenskaber såsom smag og duft, som er forskellig for hvert subjekt (Koch, 1995, s. 190).Klassisk AIDen elektroniske computer som næsten alle har derhjemme fik først sit gennembrud under anden verdenskrig. Her blev den brugt til at kunne beregne projektilbaner for missler og lignede, samt afkode den kryptering som modstanderne anvendte for at holde deres kommunikation hemmelig (Johansen, 2003, s. 11). Før denne tid anvendte man mekaniske computere, som var bygget til at kunne udføre eet bestemt stykke arbejde og ikke andet. Her
kommer matematikeren Alan Turing ind i billedet, da han allerede tilbage i 1936 forestillede sig en maskine, som kunne udføre mange forskellige typer af opgaver, ved blot at være programmeret korrekt samt have den rette mængde tid og hukommelse.Men Turing havde ikke bare haft den elektroniske computer i mente, men han var også den første til at stille spørgsmålet om hvorvidt computere er i stand til at tænke. Det er her den meget kendte test, Turingtesten kommer fra, da testen kan bevise hvorvidt en computer kan tænke selvstændigt. Testen går ud på, at man har to personer og en computer, hvor den ene person er eksaminator, som der stiller en række spørgsmål til computeren og mennesket. Disse spørgsmål bliver så besvaret og givet tilbage til eksaminatoreren, som der derefter skal forsøge at udpege hvilken af besvarelserne er computeren. Hvis computeren kan narre eksaminatoreren til at tro den er mennesket, så må computeren ifølge testen altså kunne tænke.Turing var selv klar over, at spørgsmålet om hvorvidt en computer kan tænke, er et spørgsmål som vi ikke engang kan besvare om os selv. Vi ved ikke hvilke ting der foregår inde i vores hjerne for at kunne tænke, hvilket også gør det svært at besvare spørgsmålet. Vi kan dermed ikke anvende den menneskelige måde at tænke på, som en målestok for hvordan andre ting skal eller kan tænke. Men vi ser eksempler på computerprogrammer, som der forsøger at bestå Turingtesten hvert år ved Loebnerprize-konkurrencen. Der er indtil videre ikke nogen der har bestået testen, men vi har set mange forskellige programmer, som der fremstår et intelligent menneske, som kan løse opgaver samt kunne have en flydende samtale. Selve programmeringen af disse maskiner, om hvorvidt de skulle blive programmeret fra bunden eller om den skal være i stand til at lære tingene over tid, vidste Alan Turing ikke (Johansen, 2003, s. 13).Formelle systemer er systemer, hvor computeren flytter rundt på nogle symboler ud fra nogle syntaktiske regler, for eksempel en ligning x+2=4, hvor computeren forstår at den kan flytte2-tallet over på den anden side af lighedstegnet og derefter udskifte 4-tallet med 2 (da den allerede ved at 4 - 2 = 2) (Johansen, 2003, s. 14). Vi har altså et symbolparadigme, hvor både Turingtesten og de formelle systemer bidrager til hvordan vi som mennesker tænker og forsøge at overføre det over til computere. Det kan derfor også siges, at det giver en form for metafysik, da bevidstheden er til hjernen, hvad programmet er til computeren. Vi ved altså hvordan vi skal forsøge at lave kunstig intelligens.Hele det er med at forsøge at lave kunstig intelligens, skaber det vi kalder for Cognitive Science feltet, altså undersøgelsen af menneskelig intelligens gennem forståelsen af hvordan computeren "tænker". I Klassisk AI forsøger man at lære fra mennesket til maskinens kapacitet, men hvor man med Cognitive Science ser på maskinen og forsøger at overføre det over til mennesket. Tænkning er altså symbolmanipulation, og dermed føder man altså det paradigme vi kalder for symbolparadigmet, som vi kender fra Klassisk AI.Klassisk AI skal altså forstås som en computer der kan udføre en række forskellige opgaver ud fra nogle bestemte givne regler. Denne form for AI er for eksempel set i forbindelse med skak. Her har vi fortalt computeren hvordan spillebrættet ser ud, hvilke træk hver brik har og hvordan man kan vinde spillet. Herefter kan computeren så regne ud alle de mulige træk der
findes i et skakspil og derefter udpege hvilket træk der vil være det bedste i hver eneste situation. Men efter blot et par træk, så bliver mængden af mulige træk så stort, at mange computere ville "bryde sammen", som bliver kaldt for eksponentiel eksplosion problemet (Johansen, 2003, s. 16). Dette problem kan blive løst gennem tommelfingerreglen, som trimmer mængden af muligheder, til kun at være det bedste par stykker i hver situation.Klassisk AI ser vi hele tiden, i vores lommeregnere på vores mobiler eller computere, i vores sociale medier hvor vi bliver vist forskellige reklamer eller opslag alt efter hvad en algoritme mener du vil kunne lide og chatbots som forsøger at bestå turingtesten, ved at lade som om den er et menneske.Kritik af den klassiske AIProblematikken med denne form for AI er dens manglende mængde af egen intelligens. Den kan måske slå dig i skak, men den er ikke i stand til at improvisere eller foretage andre handlinger på baggrund af en given situation. Ud fra Thomas Hobbes, så kan Klassisk AI heller ikke træffe sine valg på baggrund af følelser eller af fri vilje, hvilket gør denne form for intelligens ikke kan sammenlignes med den menneskelige. Denne form for kunstig intelligens er også nævnt som svag AI, hvilket betyder at computeren forsøger at efterligne nogle aspekter af den menneskelige intelligens. Dermed er der en manglende intelligens i denne form for AI, men hvad vil det helt præcis sige at være intelligent?Ordet intelligent betyder at forstå eller at sanse på latin, hvor empiristerne ændre betydning af ordet til forståelse i 1600-tallet. I løbet af 1800-tallet begynder ordet er blive brugt af psykologer, hvorefter man udvikler en test til at udpege de dumme skolebørn. Denne intelligenstest kender de fleste i dag som IQ-testen, hvor man gennem ens intelligensalder divideret med ens levealder giver en score, hvorefter man kan vurderer ens intelligens.Intelligens bliver altså blot et nummer i disse tests, men i forhold til kunstig intelligens, så er det selve ordet "forståelse" som der er interessant.Her kommet stærk AI ind i billedet, da man har at gøre med en kunstig intelligens, som tænker og udfører opgaver på præcis samme måde som vi mennesker gør. Dette er tror filosoffen John Searle ikke helt på, da han mener at der er ikke noget mentalt inde i computeren og computeren forstår ikke betydningen af de ting der bliver stillet overfor den. Dette forklarer Searle gennem sit eksempel "Chinese room" (Searle, 1981, s. 284), hvor man forestiller sig et menneske sidde inde i et rum fyldt med arkiver med alle mulige kinesiske tegn og en manual, hvori der står præcis hvilke tegn man skal udskrive, hvis en bestemt kombination af tegn forekommer. Personen skal altså blot kigge på den besked der kommer ind i rummet også kigge i manualen for at finde præcis de tegn i beskeden, hvorefter manualen så fortæller hvilke tegn der skal udskrives. Personen inde i rummet har altså ingen ide om hvad nogle af tegnene betyder, men kan altså stadig udføre arbejdet, hvor det også lader til at personen faktisk kan kinesisk.
Gennem det eksempel, påviser Searle, at bare fordi en computer kan narre en til at tror det er et mennesket, så er der nødvendigvis ikke tale om en stærk AI. Computeren opnår først stærk AI, når den faktisk kan forstå tegnenes betydning, hvilket Searle mener at det vil en computer aldrig vil kunne udrette. Den stærke AI, som Searle forklarer, hjælper os ikke med at forstå hvordan man tænker, da det ikke handler om maskiner, men om programmer, som i sig selv ikke er tilstrækkelig nok til at kunne tænke selvstændigt (Searle, 1981, s. 282).Lignende udmelding kom fra filosoffen Hubert Dreyfus, som skrev "What computers still can't do" i 1992, hvori han også beskriver at det er umuligt at programmerer en computer til at simulerer hvordan vores hjerne fungerer, fordi AI er karakteriseret ved brug af logik (Pettersen, 2018, s. 1061). Computeren kan være gode lommeregnere, men de vil aldrig kunne løse komplekse problemer, da de vil overse vigtige roller og samspil mellem vores krop og sanser som et intelligent individ.Dette bringer os tilbage til Descartes og Hobbes, hvor vi igen kan sige, at så længe en computer ikke har følelser, så træffer den ikke beslutninger på samme måde som mennesker og det samme angår den frie vilje, at hvis computeren ikke kan overveje dens beslutninger, så har vi ikke tale om en stærk AI. Descartes ide med at kunne opfatte vores tankeproces gennem symbolsk repræsentation, at hvis man kan lave symbolske og logiske notationer og overføre det til en computer, så er Descartes ønske om god tænkning også opfyldt.Den amerikansk filosof Jerry Fodor (1935 - 2017) introducerede tankesprogmodellen, som går ud på at vi mennesker tænker i samme baner som en computer. Vores hjerne er konstrueret på sådan en måde, at når en bestemt fysisk tilstand opstår, så vil betydningen for de foregående tilstande udgøre et logisk bevis (Johansen, 2003, s. 38). Han mener altså at denne model er den eneste måde at forklare den struktur og systematik der foregår i menneskets tænkning. Dermed argumenterer Fodor, at den klassiske AI's formelle systemer kan indpasses i en model for menneskelig tænkning.Denne model og Fodors tanker er blevet kritiseret på flere punkter, blandt andet, at vores hjerne er markant langsommere og dårligere til at håndtere den type af beregninger som computere skal kunne udføre, samt ved brug af "The Chinese Room" argumentet, at bare fordi computeren kan komme frem til det rigtige svar, så betyder det ikke at den faktisk har lært noget.Moderne AIModerne AI er anderledes på den måde, at man forsøger at lade computeren tænke på samme måde som mennesker i den forstand, at den er nødt til at lære tingene fra bunden. I vores menneskehjerne er der mere end 100 milliarder af nerveceller, som er forbundet med hinanden i et stort netværk (Johansen, 2003, s. 24). Hver neuron kan sende signaler til hinanden omkring 100 gange i sekundet, men hvis vi sammenligner det med den moderne
computer, som kan skifte tilstand mere end en milliard gange i sekundet, så arbejder vores hjerne forholdsvis langsomt.Denne form for læring bliver kaldt for et neuralt netværk, som der har en stor succes i genkendelse af mønstre. For eksempel, ved at give netværket en række forskellige håndskrevet tal, så vil den over tid kunne genkende formen på tallet og derefter kunne udskrive hvilket tal der bliver vist. Den store forskel mellem denne form for AI og den klassiske, er at det neurale netværk lærer at sine fejl, frem for at have en række syntaktiske regler gældende. Vi kan programmere hvor meget netværket skal lære at sine fejl, altså hvis outputtet er forkert, så kan vi justere vægtene til at systemet begynder at kunne genkende det rigtige tal.Denne teknologi bliver anvendt mange steder og et eksempel vil være den forholdsvis nye teknologi inden for ansigtsgenkendelse. Her har man gennem millioner af billeder kunne lave et program, som kan genkende folks ansigt og bruge det til eksempelvis at åbne ens låste mobiltelefon. Det samme ser vi ved anbefalingslister på Netflix eller Spotify, hvor den aflæser dine yndlingsserier eller musik og forsøger derefter at anbefale noget lignende. Ved at anvende eller afvise disse anbefalinger, så forbedre du de næste forslag og dermed "lærer" programmet dig bedre. Denne form for AI vil være lang mere kompliceret for klassisk AI, da den på ingen måder vil kunne spå hvilket ting hver eneste person præfererer. Der findes ikke nogle bestemte regler eller logikker som klassisk AI kan anvende til at kunne udføre den slags opgaver.Et andet andet eksempel hvor vi ser det moderne AI slå det klassiske er inden for videospil genre. Som tidligere nævnt, så er klassisk AI ofte blevet brugt til at slå stormestere i skak, men i mere komplicerede spil, så vil der efter alt for mange beregning at udføre selv med tommelfingerreglen anvendt. Her kommer neural network igen ind i billedet, dette ses eksempelvis i videospillet DOTA 2, spiller man fem mennesker mod fem andre mennesker om at ødelægge hinandens base. Der er over 100 forskellige karakterer at vælge imellem, hvor alle har forskellige evner og egenskaber. Her har firmaet OpenAI udviklede en AI der er i stand til at slå verdensmestrene i DOTA 2 efter 45.000 timer træning (OpenAI, 2019).Det sidste eksempel jeg vil præsentere er Google Duplex (Google, 2018), som er en tilføjelse til Google Assistent som er Google's digitale assistent til at kunne udføre simple kommandoer gennem stemmegenkendelse. Her har Google formået gennem et neural network, at kunne ringe til restauranter eller andre servicevirksomheder på vegne af deres brugere ved brug af kunstig intelligens. Man kan altså blot sige til Google Assistent at man ønsker en frisørtid ved et bestemt tidspunkt også ringer den automatisk til frisøren og aftaler tiden uden du selv skal deltage i samtalen. Det er utroligt svært at kunne høre hvorvidt det er et menneske eller en robot man snakker med, især når robotten også tilføjer pauseord så som "øhh" og "mhm" til samtalen. Men denne teknologi vil google ikke kun bruge til at hjælpe deres Google Assistent brugere, men også anvende det til at indsamle information angående butikkers åbningstider i helligdage perioder.Her vil de syntaktiske og logiske regler som klassisk AI ikke opnå det samme resultat, da der i løbet af telefonsamtaler kan opstå en masse uforudseende hændelser. På samme tid, så
har John Searle ret i, at denne form for AI heller ikke opnå ny viden i hvordan vi som mennesker tænker, men hvor den på nogle punkter afviger fra Hubert Dreyfus tanker om at kunstig intelligens aldrig vil kunne løse komplekse problemer, på grund af manglende sanser. Dette gør Google Duplex, da den lyder som et hvilket som helst menneske og får samtalen til at virke komfortabel.Diskussion af kunstig intelligensKunstig intelligens er noget som der er blevet diskuteret gennem flere århundrede, hvor Descartes tanker om fornuft som erkendelse er starten på hvordan vi som mennesker tænker om verden. Her kommer Thomas Hubbert også ind i billedet, med hans forklaring om hvordan vi som mennesker træffer beslutninger i livet på baggrund af følelser og om hvorvidt de beslutninger taget i fri vilje. Her må man argumenterer at så længe der ikke findes stærk AI, med menneskelige sanser og krop, så vil den aldrig kunne tage beslutninger på samme måde som vi mennesker.Turingtesten viser hvordan computeren kan fremstå som et menneske, men hvor der endnu ikke er nogen der har bestået testen. De bedste forsøg på at bestå testen, har været hvor computeren har snyd eller ændret kravene for at være en tænkende computer. Her har vi altså at gøre med en svag AI, da den forsøger at efterligne et eller få menneskelige aspekter.John Searles eksempel med det kinesiske rum er tankevækkende for hvorvidt computeren faktisk lærer noget eller om den stadig bare flytter rundt på nogle symboler. Selvom vi anvender neural networks i de fleste applikationer nu til dags, så er Searles argument stadig meget valid.Klassisk AI har altså haft en indflydelse på hvordan vi mennesker tænker over hvordan vi selv tænker og om vi få maskiner til at tænke. Her opstå cognitive science, som der prøver at forstå maskiner og anvende den viden til at forstå os som mennesker. Eksempler som Google Duplex og OpenAI viser hvor langt vi er kommet fra en klassisk AI til moderne AI, som der forsøger at få computeren til at "lære" tingene overtid og dermed udføre deres opgaver mere korrekt.